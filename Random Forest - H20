#Random Forests in H20
#example - attendance (scale)

library(h2o)

set.seed (999)

#Create Training/Testing Datasets, Matrices and Set Seed
train.index <- sample(1:nrow(TBRays), 0.75*nrow(TBRays))  #indices for 75% training data

train <- TBRays[train.index, ]  #training data (607 observations)
test <- TBRays[-train.index, ]  #testing data (evaluate) (203 observations)


trainx <- as.matrix(train[, -7])   #all factors except Y
testx <- as.matrix(test[, -7])     

trainy <- as.double(as.matrix(train[, 7]))  #only Y
testy <- as.double(as.matrix(test[, 7]))


# start up h2o 
h2o.no_progress()
h2o.init(max_mem_size = "5g")

# create feature names
y <- "attendance"
x <- setdiff(names(train), y)

# turn training set into h2o object
train.h2o <- as.h2o(train)

# hyperparameter grid
hyper_grid.h2o <- list(
  ntrees      = seq(200, 500, by = 150),
  mtries      = seq(2, 7, by = 1),
  max_depth   = seq(10, 30, by = 5),
  min_rows    = seq(1, 5, by = 2),
  nbins       = seq(10, 30, by = 5),
  sample_rate = c(.55, .632, .75)
)

# random grid search criteria
search_criteria <- list(
  strategy = "RandomDiscrete",
  stopping_metric = "mse",
  stopping_tolerance = 0.005,
  stopping_rounds = 10,
  max_runtime_secs = 30*60
)

# build grid search 
random_grid <- h2o.grid(
  algorithm = "randomForest",
  grid_id = "rf_grid2",
  x = x, 
  y = y, 
  training_frame = train.h2o,
  hyper_params = hyper_grid.h2o,
  search_criteria = search_criteria
)

# collect the results and sort by our model performance metric of choice
grid_perf2 <- h2o.getGrid(
  grid_id = "rf_grid2", 
  sort_by = "mse", 
  decreasing = FALSE
)

print(grid_perf2)   
      #max_depth = 20
      #min_rows = 3
      #mtries = 4
      #nbins = 20
      #ntrees = 350
      #sample_rate = 0.632
      #mse = 7650883

# Grab the model_id for the top model, chosen by validation error
best_model_id <- grid_perf2@model_ids[[1]]
best_model <- h2o.getModel(best_model_id)

# Now letâ€™s evaluate the model performance on a test set
test.h2o <- as.h2o(test)
best_model_perf <- h2o.performance(model = best_model, newdata = test.h2o)

# RMSE of best model
h2o.mse(best_model_perf) %>% sqrt()
## 2,880.67

#Predicting
pred_h2o <- predict(best_model, test.h2o)
head(pred_h2o)


best_model
      #number_of_trees = 350
      #min_depth = 10
      #max_depth = 17
      #mean_depth = 12.689
      #min_leaves = 97
      #max_leaves = 118
      #mean_leaves = 105.617

      #MSE = 7650883
      #RMSE = 2,766
      #MAE = 2,182
      #RMSLE = 0.1089
      #Mean Residual Deviance = 7650883




